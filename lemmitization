
#импорты
from nltk.tokenize import word_tokenize
import nltk
import pandas as pd
from string import punctuation
import pymorphy2




#определние пунктуации, стоп-слов, леммитизации
punctuations = list(punctuation)
nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('russian')
morph = pymorphy2.MorphAnalyzer()

#функция, которая будет обрабатывать текст
def preprocessing(text):
  tokens = word_tokenize(text)
  tokens_without_punct = [i for i in tokens if i not in punctuations]
  low_tokens = [i.lower() for i in tokens_without_punct]
  words_without_stop = [i for i in low_tokens if i not in stopwords]
  lemms = [morph.parse(i)[0].normal_form for i in words_without_stop]
  return lemms

#записываем в переменную text все тексты из датафрейма
data = pd.read_excel(r/content/пикабу_корпус_данных.xlsx')
text = data['text']
lst = []
counter = 0

#применяем функцию для каждого текста
while counter != len(text) -  1:
  try:
    a = preprocessing(text[counter])
    lst.append(a)
    counter += 1
  except:
    counter += 1
    continue

#записываем  новый стоблец в датафрейм
series = pd.Series(lst)
series.to_excel(r'/content/новый текст.xlsx')


#читаем датафрейм и выводим обычный и обработанный текст
import pandas as pd
df = pd.read_excel(r"C:\Users\user\Desktop\новый текст (7).xlsx")

#вывести первые 10 обычных текстов и обработанных
i = 0
while i != 10:
    print(df['text'][i])
    print(df['Обработанный текст'][i])
    i += 1
